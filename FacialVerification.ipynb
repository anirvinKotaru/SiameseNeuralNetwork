{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa5ba14-d9ef-43cc-93f9-5d0dff2501c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.12.1 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.12.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.1 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.12.1) (2.12.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (4.25.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (65.5.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (25.12.19)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (2.12.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (25.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (1.6.3)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (2.12.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (1.24.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (2.12.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (3.15.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (18.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (0.31.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (0.4.38)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (3.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (1.17.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (1.14.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (1.74.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow==2.12.1) (2.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.1->tensorflow==2.12.1) (0.45.1)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.1->tensorflow==2.12.1) (1.15.3)\n",
      "Requirement already satisfied: jaxlib<=0.4.38,>=0.4.38 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.1->tensorflow==2.12.1) (0.4.38)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.1->tensorflow==2.12.1) (0.5.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (2.32.5)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (3.1.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (3.10)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (2.47.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (2.0.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (2.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (2026.1.4)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (3.0.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\anirv\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.1->tensorflow==2.12.1) (3.3.1)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "Successfully installed typing-extensions-4.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 8.38.0 requires typing_extensions>=4.6; python_version < \"3.12\", but you have typing-extensions 4.5.0 which is incompatible.\n",
      "exceptiongroup 1.3.1 requires typing-extensions>=4.6.0; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.12.1 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff0cd01-ff1f-4d88-9816-bc8757b209bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import standard dependencies\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd17a5d-d35c-4c6f-8cdf-25c93715fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import TensorFlow Dependencies - Functional API\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea01dde-68bb-4a20-b5dd-c1862879d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid out of memory errors by setting GPU memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531cd68b-12d3-424e-bbd9-0092684d620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup paths\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdfab2a-63eb-46bb-a585-39347e6ef510",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'data\\\\positive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# make the directories\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPOS_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(NEG_PATH)\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(ANC_PATH)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'data\\\\positive'"
     ]
    }
   ],
   "source": [
    "# make the directories\n",
    "os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aacd2242-5d24-4164-bdcd-0f211c49d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('archive.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "310efea0-9730-4c5c-bb5b-bdc82ebd1298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move LFW Images to the following repository data/negative\n",
    "lfw_path = os.path.join('lfw-deepfunneled', 'lfw-deepfunneled')\n",
    "\n",
    "for directory in os.listdir(lfw_path):\n",
    "    for file in os.listdir(os.path.join(lfw_path, directory)):\n",
    "        EX_PATH = os.path.join(lfw_path, directory, file)\n",
    "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "        os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "724e03b5-a47c-482a-bed3-6de74835d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import uuid library to generate unique image names\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9711d74-6e9b-4b6c-960d-7094de3c7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish connection to webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    #crops frame 250x250 in the center kinda\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "\n",
    "    #collect anchors\n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        #create unique file path\n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        #write out anchor image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    #collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        #create unique file path\n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        #write out positive image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    #show image back to screen inside python\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "\n",
    "    #breaking gracefully\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#release webcam and destroys image show frame\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27450ac1-4983-4d7a-ad5a-467a34ef7ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(400)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(400)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7191763a-091d-4ad0-8652-517ba922b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    #read image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "\n",
    "    #load in the image\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "\n",
    "    #preprocess (resize to 100x100x3)\n",
    "    img = tf.image.resize(img, (100,100))\n",
    "\n",
    "    #scale image to 0-1\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0acc7f32-c419-447e-b9a8-d219849a7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating labeled dataset\n",
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59b2704c-f21c-412e-8a2a-c3876358ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build test train partition\n",
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc8934a0-c847-465c-b364-9a9ca9b26a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a dataloader pipeline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bda61350-5737-414f-9eab-e7be62e3be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc3b150f-e7dd-4e71-8f16-18ae70699815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47dae38c-5c0f-45d6-8f9f-0c991f3245df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inp = Input(shape=(100,100,3), name = 'input_image')\n",
    "\n",
    "    #first block\n",
    "    c1 = Conv2D(64, (10, 10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "\n",
    "    #second block\n",
    "    c2 = Conv2D(128, (7, 7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "\n",
    "    #third block\n",
    "    c3 = Conv2D(128, (4, 4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "\n",
    "    #final block\n",
    "    c4 = Conv2D(256, (4, 4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a67f9e2a-0c58-4200-a83d-bd303fbd261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37a64ff4-6d1f-4a7a-913f-3db5706dc797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 46, 46, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 20, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,960,448\n",
      "Trainable params: 38,960,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7524921c-9451-42d0-93e7-04a7605db53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Siamese l1 Distance Class\n",
    "class L1Dist(Layer):\n",
    "\n",
    "    #Init method (inheritance)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    #rivers combine (similarity calculation)\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8622ea00-efc2-4db2-a4fc-59221829db3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "\n",
    "    #anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(100,100,3))\n",
    "    \n",
    "    #VALIDATION image input in the network\n",
    "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
    "\n",
    "    #Combine siamese distance components\n",
    "    siamese_layer = L1Dist(name='distance')\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "\n",
    "    #Classification Layer\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de14e16a-04d2-4ac6-a849-ea27aefdc316",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20d63312-e4fb-4388-8477-c397fd75a0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_img (InputLayer)         [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " validation_img (InputLayer)    [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
      "                                                                  'validation_img[0][0]']         \n",
      "                                                                                                  \n",
      " l1_dist_1 (L1Dist)             (None, 4096)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            4097        ['l1_dist_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,964,545\n",
      "Trainable params: 38,964,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc23cd4-e012-4d5a-8032-4cfea721162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "#Set up Loss and Optimizer\n",
    "binary_cross_loss = tf.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f30d3-5769-46d9-80f6-5b734ed60f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizer.Adam(1e-4) #0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639b38a-8e94-447c-8189-5b074d27b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model = siamese_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
